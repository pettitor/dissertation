\section{Background and Related Work}\label{sec:cloud:related_work}
This section provides related work relevant to this chapter.
First, we discuss studies regarding energy efficiency in data centres in \refsec{sec:cloud:data_centers},.
Then, we focus on research on mobile network traffic characteristics, to be used in \refsec{sec:cloud:virtualized_network_functions}.
Finally, we focus on crowdsourcing research and provide background information for \refsec{sec:cloud:crowdsourcing}.

\subsection{Simulative Evaluation of Hierarchical Caching Systems}
Several papers have been published, proposing new architectures for data centres which provide more resilience or are more cost effective\cite{Al-Fares2008, Greenberg2009a, Guo2009}.

Bolla et al.~\cite{Bolla2011} provide an overview over approaches to reduce energy consumption caused by network infrastructure, offering a complementary view to the methods suggested in this chapter.

Heller et al.~\cite{Heller2010} published a paper considering the tradeoff between energy efficiency and resilience.
They use the fat-tree architecture similar to~\cite{Al-Fares2008, Greenberg2009a} which is based on commercial of-the-shelf network equipment.
During normal network operation, the additional switches used for backup paths are switched off and only turned on in case of high load or network failures.
The proposed mechanism is implemented in a testbed where OpenFlow is used for the switch management.
However, they only turn off the switches and not the servers, which only consume between \SIrange{5}{10}{\percent} of the overall energy consumption.

Kliazovich et al.~\cite{Kliazovich2010} developed a simulation environment for computing the energy consumption of different data centre architectures. In addition to showing the share of network and server energy consumption, they present how much energy can be saved while using dynamic voltage and frequency scaling or dynamic power management.

One of the first paper presenting a dynamic resource management according to the offered load  is presented by Chase et al.~\cite{Chase2001}. They propose an architecture where server clusters are dynamically resized in accordance to the negotiated SLAs.

A more detailed approach is presented by Chen et al.~\cite{Chen2005}. Three solutions are proposed to reduce the power consumption of servers in a data centre.
For the first solution, the workload behaviour of the near future is predicted while the second solution is a reactive solution, using periodic feedback of system execution.
The third proposed solution is a hybrid solution using a combination of prediction and periodic feedback.

The goal of the authors in~\cite{Mazzucco2010a, Dyachuk2010, Mazzucco2010b} is to run a minimum number of servers in a data centre to maximise the revenue of the service provider.
The considered data centre hosts a web page application. While in~\cite{Mazzucco2010a} the authors do not consider user impatience and the fact that servers consume energy without producing revenue during wake up, \cite{Mazzucco2010b} takes both into account. In~\cite{Dyachuk2010}, the authors introduced a policy for dynamically adapting the number of running servers. The goal of the paper was to find the best tradeoff between consumed power and service quality.

In~\cite{Gandhi2010} the authors present a model for server farms using exponential inter-arrival, service and setup times. They consider different policies for powering down servers for finite and infinite servers.


\subsection{Mobile Network Traffic Characteristics}
The authors of \cite{Metzger2014} which include a co-author of~\cite{Metzger2014a}, the basis for \refsec{sec:cloud:virtualized_network_functions}, provide a detailed evaluation of mobile network traces taken from a large European mobile network operator.

Having access to core network datasets, the authors of~\cite{Shafiq2011, Paul2011} both take the approach of looking at high-level user traffic characteristics, focusing on temporal and spatial variations of user traffic volume and investigating the influence of different devices on this metric.
Additional user flow and session traffic metrics are being studied in~\cite{Zhang2012} with the conclusion that, in comparison to wired traffic, short flows are occurring more frequently.
In 2006, a core network measurement study of various user traffic related patterns was conducted, providing an initial insight into \gls{PDP} context activity and durations~\cite{Svoboda2006}.

In~\cite{Lee2007}, mobile network traces are used to simulate a malicious signalling storm by transmitting low-volume user plane traffic with specially crafted inter-departure times, causing constant signalling.
The authors of~\cite{Romirer-Maierhofer2008} investigate influence of core network elements on one-way delays in mobile networks.

\subsection{Analytic Evaluation of Hierarchical Caching Systems}
The vast expansion of streaming services and content delivery networks (CDNs) suggests addressing content by content centric networking (CCN), to enable effective traffic management.
Addressing content instead of physical servers allows utilizing local resources.
To enable addressing, content is identified with unique names.
Available storage in routers is used to cache content in these approaches.
Since the tree like structure of the routers spreads on the way to the end user, the content replication scales with the content demand.
Simulative evaluation of tree like content delivery networks is provided in \cite{lareida2015augmenting} considering overlays and inter-domain traffic cost according to AS relationships.
In \cite{applegate2010optimal} hierarchical content delivery networks with bandwidth consraints are evaluated by simulation. The impact of using edge resources with limited capacity for content delivery on QoE is evaluated by means of simulation in \cite{info3-inproceedings-2015-530}.

In the following we give a brief overview of analytic models for the evaluation of mechanisms in CDN and CCN architectures.
In \cite{fricker2012impact} a two tiered caching architecture is investigated, where the first tier consists of home gateways in access networks.
The second tier consists of data centers in the core network.
Requests that cannot be served in the first tier are forwarded to the second tier.
The popularity of objects follows a power-law and is modeled by the Zipf-law, which is observed for different types of content distributed in the Internet, including video \cite{gill2007youtube,cha2009analyzing}.
As cache replacement strategy Least-Recently-Used is assumed.
To analyse the performance of LRU caches, models exist that assume negative exponentially distributed inter-arrival times of object requests at the cache \cite{che2002hierarchical}. 
The requests are generated according to the independent reference model (IRM), which assumes identically and independently distributed requests of a set of objects.
It is shown in \cite{fricker2012versatile} that the model also applies in more general conditions.
The model also provides accurate results for a high number of objects with varying file sizes.
In \cite{martina2014unified} the model is extended, to analyze advanced caching strategies like {$k$-LRU}, where objects have to pass a certain number of $k-1$ virtual caches to be stored in the actual cache.
The virtual caches replace objects according to LRU and store only meta information.
The IRM assumptions are generalized in order to apply to effects of temporal locality in the request process.
The model for LRU can be further extended to evaluate the performance of general cache networks \cite{rosensweig2010approximate, martina2014unified}.
Further caching strategies with limited memory, like W-LFU and Geometrical Fading, are investigated in \cite{hasslinger2014caching}.
The Sliding Window strategy applies the LFU approach to the frequency of requests in a limited time frame.
Geometrical Fading scores recent requests with a factor that decreases according to a geometric sequences with the number of intermediate request.

The analytic models do not consider the service time of requests, which is limited by the bandwidth of the uplink of the cache.
In this work we consider a tiered caching architecture, where the upload bandwidth of the caches is highly limited.
%A limited bandwidth or service time of the caches is not considered in any of the above analytic models.
The paper closest to this works is \cite{valancius2009greening} which proposes the NaDa approach and develops an optimal content placement on NaDas.
The performance of the approach is evaluated with traces only.
To determine the performance analytically the system with bandwidth constraints is modeled as loss network consisting of a server for each of the caches. The exact stationary distribution of the loss network is too complex to evaluate.
In \cite{tan2013optimal} the system is analyzed under large system asymptotics where simplifications occur.

We use a different approach by approximating the arrival of rate requests.
This allows us to effectively assess the loss probability by using a simple form of the Erlang formula for a loss network.
%We combine the

To optimize the content placement adaptively \cite{leconte2014adaptive} propose Least-Recently-Lost (LRL) replacement, which tries to optimize the loss rate in the first tier.
A different approach is proposed by \cite{zhou2015unifying} which allocates bandwidth resources instead of content copies proportionally to the content popularity.

\subsection{Evaluation of Social Aware Traffic Management Mechanisms}
