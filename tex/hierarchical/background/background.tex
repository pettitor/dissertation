\section{Background and System Description}\label{sec:cloud:related_work}
This section provides related work relevant to this chapter.
First, we discuss ... in \refsec{sec:cloud:data_centers},.
Then, we focus on ..., to be used in \refsec{sec:cloud:virtualized_network_functions}.
Finally, we focus on ... \refsec{sec:cloud:crowdsourcing}.

\subsection{System Model for Hierarchical Caching Systems}

\begin{figure}[tb]
\centering
\includegraphics[width=75mm]{hierarchical/analyticbw/figures/hcmodel}
\caption{System model.}
\label{fig:hcmodel}
\end{figure}

To model the content delivery network, we consider a set of caches $\Gamma$ that is organized in a tiered caching architecture as depicted in figure~\ref{fig:hcmodel}. Each cache in $\Gamma$ has a certain cache capacity $C$, which specifies the number of content items it can store.
Consider that the method can also be applied to content with varying file size, if the content items are organized in equally sized chunks, or if the sums are weighted accordingly.
Tier-1 caches have capacity $C_1$ and tier-2 caches have capacity $C_2$.
Here we assume, that the cache capacity of all tier-1 caches is equal.
This is for example the case if the caches are deployed by a provider on home gateways.
If the caches are set up by end-users the cache capacities may vary.
Each tier-1 cache $i$ has a specific average upload throughput $\rho_1(i)$.
Content items are requested from a catalog with size $N$.
Each item $m\in \{1,2,\dots,N\}$ is requested with rate $\lambda_m$.
The total arrival rate of requests is $\lambda=\sum_{m=1}^N \lambda_m$.
%\begin{equation}
%\lambda=\sum_{m=1}^N \lambda_m \, .
%\end{equation}

The arrival rate of requests for an item can then also be expressed with the probability $p_m$ that item $m$ is requested:

\begin{equation}
\lambda_m = p_m \lambda \, , \text{where} \, \sum_{m=1}^N p_m = 1 \, .
\end{equation}

%We consider a sharing probabilty $p_{share}$ which specifies the share of home gateways in the AS that supports the caching functionality and serves as tier-1 cache.

%\begin{itemize}
%	\item Number IP-Adresses -> Number of Routers
%	\item Caches and Sharing Probability
%  	\item Replication Factor -> optimize with http://conferences.sigcomm.org/co-next/2009/papers/Valancius.pdf and http://arxiv.org/pdf/1004.4709.pdf
%  	\item Capacity of an AS, effective cache capacity
%    \item ratio upload download bandwidth -> should ISPs change their contracts?
%  \item locality of requests -> higher potential of the overlay
%\end{itemize}

\begin{table}[tb]
\centering
\caption{Notation of the paper.}
\label{tab:notation}
\begin{tabular}{|c|c|c|}
\hline
param. & description & default \\
\hline
$N$ & catalogue size & 1e6 \\
$n_{1}$ & number of tier-1 caches & 1e4 \\
$n_{2}$ & number of tier-2 caches & 1 \\
$C_{1}$ & tier-1 cache capacity & 8 \\
$C_{2}$ & tier-2 cache capacity & 1e4 \\
$\rho_{1}$ & tier-1 cache upload bandwidth & 0.8Mbps \\
$\lambda_m$ & arrival rate of requests for object $m$& \\
$b_m$ & bit rate of object $m$& \\
$d_m$ & duration of object $m$& \\
%%$\bar{\lambda}$ & average arrival rate of requests& \\
%$r_m$ & number of replications of object m& \\
\hline
\end{tabular}
\end{table}

\subsection{Content Popularity and Arrival Processes}

\section{Performance Evaluation of Hierarchical Caching Systems}
The vast expansion of streaming services and content delivery networks (CDNs) suggests addressing content by content centric networking (CCN), to enable effective traffic management.
Addressing content instead of physical servers allows utilizing local resources.
To enable addressing, content is identified with unique names.
Available storage in routers is used to cache content in these approaches.
Since the tree like structure of the routers spreads on the way to the end user, the content replication scales with the content demand.
Simulative evaluation of tree like content delivery networks is provided in \cite{lareida2015augmenting} considering overlays and inter-domain traffic cost according to AS relationships.
In \cite{applegate2010optimal} hierarchical content delivery networks with bandwidth consraints are evaluated by simulation. The impact of using edge resources with limited capacity for content delivery on QoE is evaluated by means of simulation in \cite{info3-inproceedings-2015-530}.

\subsection{Analytic Model for LRU Caches}

In the following we give a brief overview of analytic models for the evaluation of mechanisms in CDN and CCN architectures.
In \cite{fricker2012impact} a two tiered caching architecture is investigated, where the first tier consists of home gateways in access networks.
The second tier consists of data centers in the core network.
Requests that cannot be served in the first tier are forwarded to the second tier.
The popularity of objects follows a power-law and is modeled by the Zipf-law, which is observed for different types of content distributed in the Internet, including video \cite{gill2007youtube,cha2009analyzing}.
As cache replacement strategy Least-Recently-Used is assumed.
To analyse the performance of LRU caches, models exist that assume negative exponentially distributed inter-arrival times of object requests at the cache \cite{che2002hierarchical}.
The requests are generated according to the independent reference model (IRM), which assumes identically and independently distributed requests of a set of objects.
It is shown in \cite{fricker2012versatile} that the model also applies in more general conditions.
The model also provides accurate results for a high number of objects with varying file sizes.
In \cite{martina2014unified} the model is extended, to analyze advanced caching strategies like {$k$-LRU}, where objects have to pass a certain number of $k-1$ virtual caches to be stored in the actual cache.
The virtual caches replace objects according to LRU and store only meta information.
The IRM assumptions are generalized in order to apply to effects of temporal locality in the request process.
The model for LRU can be further extended to evaluate the performance of general cache networks \cite{rosensweig2010approximate, martina2014unified}.
Further caching strategies with limited memory, like W-LFU and Geometrical Fading, are investigated in \cite{hasslinger2014caching}.
The Sliding Window strategy applies the LFU approach to the frequency of requests in a limited time frame.
Geometrical Fading scores recent requests with a factor that decreases according to a geometric sequences with the number of intermediate request.

\subsection{Evaluation of Caching Systems with Limited Capacity}

The analytic models do not consider the service time of requests, which is limited by the bandwidth of the uplink of the cache.
In this work we consider a tiered caching architecture, where the upload bandwidth of the caches is highly limited.
%A limited bandwidth or service time of the caches is not considered in any of the above analytic models.
The paper closest to this works is \cite{valancius2009greening} which proposes the NaDa approach and develops an optimal content placement on NaDas.
The performance of the approach is evaluated with traces only.
To determine the performance analytically the system with bandwidth constraints is modeled as loss network consisting of a server for each of the caches. The exact stationary distribution of the loss network is too complex to evaluate.
In \cite{tan2013optimal} the system is analyzed under large system asymptotics where simplifications occur.

We use a different approach by approximating the arrival of rate requests.
This allows us to effectively assess the loss probability by using a simple form of the Erlang formula for a loss network.
%We combine the

To optimize the content placement adaptively \cite{leconte2014adaptive} propose Least-Recently-Lost (LRL) replacement, which tries to optimize the loss rate in the first tier.
A different approach is proposed by \cite{zhou2015unifying} which allocates bandwidth resources instead of content copies proportionally to the content popularity.

\subsection{Evaluation of Caching Systems with Dynamic Content Popularity}
